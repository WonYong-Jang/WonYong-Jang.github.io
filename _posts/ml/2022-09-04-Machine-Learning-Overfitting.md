---
layout: post
title: "[Machine Learning] 오버피팅의 개념과 해결 "
subtitle: "Overfitting(과적합), Data Augmentation" 
comments: true
categories : ML
date: 2022-09-04
background: '/img/posts/mac.png'
---

## 1. Overfitting(과적합)

학습이 반복되면서 학습의 정확도(accuracy)가 올라간다. 이상적인 학습이란 
데이터가 계속 들어와 학습이 반복되면 될수록 accuracy가 높아지게될 것이다.   

`하지만 이 과정에서 학습 모델이 주어진 데이터에 너무 과하게 맞춰져서(overfit) 
    조금이라도 다른 데이터만 들어와도 다른 결과로 예측하여 결과적으로 
    정확도가 낮아지는 현상을 Overfitting 이라고 한다.`    

> 예를 들어, 노란색 고양이를 보며 고양이의 특성을 학습한 모델이 
검은색이나 흰색 고양이를 보고는 그것을 고양이라고 인식하지 못하는 현상이 
overfitting과 유사한 경우이다.   

즉, overfitting은 모델의 파라미터들을 학습 데이터에 너무 가깝게 맞췄을 때 
발생하는 현상이다.   
아래 그림을 보자.   

<img width="600" alt="스크린샷 2022-09-04 오후 11 56 32" src="https://user-images.githubusercontent.com/26623547/188319934-aef6518e-1895-4683-b99d-9024b8b4fe56.png">   

각 점들은 학습 데이터, 선은 머신러닝이 생성한 모델이라고 볼 수 있다.   
위 모델은 개별 점들을 하나도 놓치고 싶지 않아서, 이 현상을 
어떻게든 완벽하게 설명하고 싶어 모두 따라가며 선을 그리고 있다.   

> 이게 바로 overfitting이 된 예이다.   

그런데 실제 현상도 이렇게 구불구불한 선을 따라서 나타날까?    
아닐 수 있다. 우리는 적당히 큰 그림을 볼 필요가 있다.   
그래야 전체적인 추세나 패턴이 보이고, 제대로 된 인사이트를 얻어 
에측을 해낼 수 있다.   

만약 학습 데이터를 통해 전체적인 패턴을 유추하면 아래 그림과 같은 선을 
그릴 수 있다.   

<img width="600" alt="스크린샷 2022-09-04 오후 11 56 38" src="https://user-images.githubusercontent.com/26623547/188319937-ca963efb-8055-4173-97d7-4d37fc5c538b.png">    

`결국 overfitting은 너무 세밀하게 학습 데이터 하나하나를 다 설명하려고 하다보니 
정작 중요한 패턴을 설명할 수 없게 되는 현상을 말한다`    

그럼 이 문제를 어떤 방식으로 다루고 해결해야 할까?   

- - - 

## 2. Overfitting 문제를 해결하는 방법    


#### 2-1) 일단 데이터부터 자세히 살펴보기   

데이터에서 중요한 통계치들을 면밀히 봐야한다.   
변수들의 평균과 중앙값은 물론이고, 예를 들면 pandas의 groupby와 같은 메서드를 
사용해서 반드시 집단별 통계치를 확인해야 한다. 

그게 곧 머신러닝의 학습하게 될 패턴이기 때문에 
데이터 확인할 때 가장 도움이 되는 건 역시 시각화(visualization)이다.   

#### 2-2) 애초에 적절하게 수집된 데이터인지 확인하기   

머신러닝 모델을 적용하고자 하는 모든 집단으로부터 골고루 수집된 데이터인지 
확인할 필요도 있다.    
수집된 데이터가 특정 장면에만 적용되는 것이라면 애초에 보편적으로 적용할 수 있는 
모델이 아니기 때문이다.   
`특정 집단의 특성만 반영할 가능성이 높기 때문에 데이터 수집 단계에서부터 신중했는지 
검토하자.`   

#### 2-3) 학습 데이터 보강(Augmentation)하기   

예를들어 불법 신용카드 거래를 감지하는 머신러닝 모델을 생성한다고 가정해보자.   
우선 모든 거래 중 불법 거래는 거의 없을 테니 모든 거래가 합법적이라고 
에측하는 무식한 모델을 만들어놔도 매우 높은 정확도를 얻게 될 수 있다.    

물론 정확도 외에 다른 지표들로 모델의 성능을 평가할 수 있다.   
[분류모델 성능지표](https://wonyong-jang.github.io/ml/2022/09/01/Machine-Learning-Classification-Metric.html)를 통해 확인해보자.   

아무튼 이 문제를 해결하려면 학습 데이터에 내가 가지고 있던 사례의 특성들을 
조금씩 조작해서 추가시켜주는 방법이 있다.   
위 예시에서 만약 애초에 내가 가지고 있던 학습 데이터에 사기 거래가 2건 밖에 
없었다면 이 알고리즘은 그 2건이 가진 특성에 대해서만 완전히 꽂혀버려서 
당연히 오버피팅이 발생할 수 밖에 없을 것이다.   
`그래서 조금씩 다른 사기 거래 케이스를 조작적으로 추가시켜서 다양한 케이스를 
확보하여 오버피팅을 줄여주는 방법이다.(이를 Data Augmentation이라고 부른다.)`     

이런 작전은 이미지 분류에서 특히 많이 사용되는데, 만약 동물 사진을 
분류하는 모델이라고 한다면 멀쩡한 이미지뿐만 아니라 그 사진들을 
회전시키거나 약간 찌그러트린 수정본들도 함께 학습시키는 것이다.    


#### 2-4) 학습 데이터에 포함될 특성(featureset)을 제한하기   

대표적인 예시로 [Amazon 채용 프로그램에 인공지능(AI) 시스템](https://www.bbc.com/korean/news-45820560)을 적용했다가 
결국 폐기했다는 사실이 이슈가 된 적이 있다.      

> 해당 모델이 추천한 지원자 대부분이 남성을 추천하여 overfitting이 발생하였다.    

`(위 예시에서 성별처럼) 어떤 특성이 모델에 영향을 과도하게 미치는 경우에는 
오히려 해당 특성을 제거하고 모델을 학습하는 전략을 짜볼 수도 있다.`    
안 그러면 다른 모든 특성이 다 똑같더라도 하나의 특성(성별) 하나가 다르다는 
이유만으로 분류나 예측을 수행하게 되는 셈인데, 이건 결국 이 모델이 
현실에서 나타나는 편견과 차별을 그대로 반영한다는 뜻이기 때문이다.   

이상적으로 생각하면 모델이 어떤 특성들을 바탕으로 분류/에측을 하길 기대하는지 
잘 생각해보고 정말 필요하다고 생각하는 특성들을 
포함시켜야 한다.    


- - -
Referrence 

<https://www.bbc.com/korean/news-45820560>    
<https://hleecaster.com/ml-overfitting/>   

{% highlight ruby linenos %}
{% endhighlight %}


{%- if site.disqus.shortname -%}
    {%- include disqus.html -%}
{%- endif -%}

