I"0<h1 id="하둡hadoop">하둡(Hadoop)</h1>

<p>하둡은 빅데이터 인프라 기술 중에 하나로 분산처리를 통해 수많은 데이터를 저장하고 
처리하는 기술이다.  <br />
하둡 프레임워크는 몇 가지 프레임워크로 이루어져 있다. 이중에서도 
<code class="language-plaintext highlighter-rouge">가장 핵심적인 기능을 하는 것은 맵리듀스(MapReduce) 프레임워크와 
분산형 파일 시스템(HDFS)이다.</code></p>

<p>하둡은 여러 대의 서버를 이용해 하나의 클러스터를 구성하며, 이렇게 클러스터로
묶인 서버의 자원을 하나의 서버처럼 사용할 수 있는 클러스터 컴퓨팅 환경을
제공한다.
기본적인 동작 방법은 분석할 데이터를 하둡 파일 시스템인 HDFS에 저장해 두고
HDFS 상에서 맵리듀스 프로그램을 이용해 데이터 처리를 수행하는
방식이다.</p>

<p><code class="language-plaintext highlighter-rouge">하둡 파일 시스템(HDFS)은 네임노드와 여러 개의 데이터 노드로 구성되며, 
    하나의 네임노드가 나머지 데이터 노드를 관리하는 형태로 동작한다.</code></p>

<p><code class="language-plaintext highlighter-rouge">데이터를 저장할 때는 네임노드가 전체 데이터를 블록이라고 하는 일정한 크기로 나눠서 
여러 데이터 노드에 분산해서 저장하는데, 이 때 각 블록들이 
어느 데이터 노드에 저장돼 있는지에 대한 메타정보를 네임노드에 기록한다.</code> <br />
<code class="language-plaintext highlighter-rouge">그리고 맵리듀스 잡을 실행 할 때 거꾸로 네임노드로부터 
메타정보를 읽어서 처리할 데이터의 위치를 확인하고 분산처리를 수행한다.</code></p>

<h2 id="맵리듀스의-원리">맵리듀스의 원리</h2>

<p>상식적으로 1명이 100개를 훑어보는 것과 100명이 1개씩 훑어보는 것이 빠를 것이다. 
이것이 분산처리의 핵심이지만 100명이 훑어본 결과를 취합하고 정리하는 소요가 
있게 마련이다. 또한 탐색할 양이 101개이거나 1개의 길이가 서로 다르다면 
이를 동일한 업무크기로 나누는 일도 쉽지가 않을 것이다.</p>

<p>맵리듀스는 이러한 처리를 돕는 역할을 한다. 이름 그대로 Map단계와 Reduce단계로 
이루어진다. 먼저 Map 단계에서는 흩어져 있는 데이터를 key, value로 데이터를 
묶어준다. 예를 들어 key는 몇 번째 데이터인지, value는 값을 추출한 정보를 가진다. 
그리고 Reduce단계는 Map단계의 key를 중심으로 필터링 및 정렬한다.</p>

<hr />

<h2 id="1-하둡-설치">1. 하둡 설치</h2>

<p>macOS에서 brew를 이용하여 쉽게 설치할 수 있다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ brew install hadoop   
</code></pre></div></div>

<p>아래와 같이 에러가 발생한다면 /usr/local/sbin 폴더를 생성하면 해결된다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>" Error: The `brew link` step did not complete successfully. The formula built, but is not symlinked into /usr/local. Could not symlink sbin/FederationStateStore. /usr/local/sbin is not writable."
</code></pre></div></div>

<hr />

<h2 id="2-하둡-설정">2. 하둡 설정</h2>

<p>하둡 설정을 위해 관련된 파일을 수정해줘야 한다. 수정해야 할 파일은 아래 경로에 있다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cd /usr/local/Cellar/hadoop/3.3.1/libexec/etc/hadoop
// 또는 Finder에서 Cmd+Shift+G 명령어를 이용하여 경로 검색
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">hadoop-env.sh</code></li>
  <li><code class="language-plaintext highlighter-rouge">core-site.xml</code></li>
  <li><code class="language-plaintext highlighter-rouge">mapred-site.xml</code></li>
  <li><code class="language-plaintext highlighter-rouge">hdfs-site.xml</code></li>
</ul>

<h4 id="2-1-hadoop-envsh">2-1) hadoop-env.sh</h4>

<p>해당하는 파일의 기존 내용이 없다면 변경에 해당하는 내용을 추가로 기재한다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>기존: export HADOOP_OPTS="$HADOOP_OPTS -Djava.net.preferIPv4Stack=true"
변경: export HADOOP_OPTS="$HADOOP_OPTS -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc=" 
</code></pre></div></div>

<h4 id="2-2-core-sitexml">2-2) core-site.xml</h4>

<p>core-site.xml 파일은 HDFS와 맵리듀스에 공통적으로 사용되는 IO와 같은 
하둡 코어를 위한 환경을 설정하는 파일이다. <br />
파일의 configuration 태그 안에 작성한다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  &lt;configuration&gt;
      &lt;property&gt;
          &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
          &lt;value&gt;/usr/local/Cellar/hadoop/hdfs/tmp&lt;/value&gt;
          &lt;description&gt;A base for other temporary directories.&lt;/description&gt;
      &lt;/property&gt;
      &lt;property&gt;
          &lt;name&gt;fs.default.name&lt;/name&gt;
          &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
      &lt;/property&gt;
  &lt;/configuration&gt;
</code></pre></div></div>

<h4 id="2-3-mapred-sitexml">2-3) mapred-site.xml</h4>

<p>mapred-site.xml 파일은 Job Tracker와 Task Tracker 같은 맵리듀스 데몬을 
위한 환경을 설정하는 파일이다.  <br />
파일의 configuration 태그 안에 작성한다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  &lt;configuration&gt;
      &lt;property&gt;
          &lt;name&gt;mapred.job.tracker&lt;/name&gt;
          &lt;value&gt;localhost:9010&lt;/value&gt;
      &lt;/property&gt;
  &lt;/configuration&gt;
</code></pre></div></div>

<h4 id="2-4-hdfs-sitexml">2-4) hdfs-site.xml</h4>

<p>hdfs-site.xml 파일은 네임노드, 보조 네임노드, 데이터 노드 등과 같이 
HDFS 데몬을 위한 환경을 설정하는 파일이다. <br />
파일의 configuration 태그 안에 작성한다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  &lt;configuration&gt;
      &lt;property&gt;
          &lt;name&gt;dfs.replication&lt;/name&gt;
          &lt;value&gt;1&lt;/value&gt;
      &lt;/property&gt;
  &lt;/configuration&gt;
</code></pre></div></div>

<hr />

<h2 id="3-하둡-실행">3. 하둡 실행</h2>

<p>하둡을 실행하기 전에 하둡 파일 시스템(HDFS)으로 포맷을 해야한다. <br />
터미널에서 다음과 같이 입력하여 HDFS로 포맷한다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cd cd /usr/local/cellar/hadoop/3.3.1/libexec/bin
$ hdfs namenode -format
</code></pre></div></div>

<p>포맷 후, 아래와 같이 ssh key를 생성하고 사용한다. <br />
key 이름과 비밀번호 입력 라인이 나올때, 빈칸으로 엔터를 
누르면 자동으로 id_rsa.pub이 생성된다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ssh-keygen -t rsa
$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys
</code></pre></div></div>

<p>이제 하둡을 실행할 때 아래와 같이 에러가 날 경우는 
원격 로그인을 허용하지 않았을 경우 발생 한다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"localhost: ssh: connect to host localhost port 22: Connection refused"   
</code></pre></div></div>

<p>환경설정의 공유에 들어가서 원격 로그인을 허용한다.</p>

<p><img width="591" alt="스크린샷 2021-08-06 오후 11 14 22" src="https://user-images.githubusercontent.com/26623547/128523833-79843bec-8a03-403b-9190-6c9d21ecd0ff.png" /></p>

<p>아래와 같이 ssh가 제대로 접속되는지 확인 할 수 있다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ssh localhost    
</code></pre></div></div>

<h4 id="3-1-실행-및-종료-명령어">3-1) 실행 및 종료 명령어</h4>

<p>하둡을 실행하고 종료하는 명령어는 다음과 같다.</p>

<ul>
  <li>실행</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cd /usr/local/cellar/hadoop/3.3.1/libexec/sbin
$ ./start-all.sh
# 또는
$ ./start-dfs.sh
# 또는
$ ./start-yarn.sh
</code></pre></div></div>

<ul>
  <li>종료</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cd /usr/local/cellar/hadoop/3.3.1/libexec/sbin   
$ ./stop-all.sh
# 또는
$ ./stop-dfs.sh
# 또는
$ ./stop-yarn.sh
</code></pre></div></div>

<p>정상적으로 실행된 것인지 알고 싶을 때 jps 명령어를 입력한다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>29171 NodeManager
28644 NameNode
29255 Jps
28745 DataNode
28206 ResourceManager
28879 SecondaryNameNode
</code></pre></div></div>

<p>참고로 start-dfs.sh 실행할때 아래와 같이 warning이 나올수 있는데, 이는 
64비트 운영체제에서 32비트 하둡을 실행하기 때문에 발생하는 에러라고 한다.  <br />
인터넷 검색해보니 해결방법이 없지는 않으나, 크게 중요한 문제는 아니라고 한다.<br />
해당 warning이 떠도 실행은 잘된다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"2018-12-16 09:22:37,400 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable"    
</code></pre></div></div>

<h4 id="3-2-하둡-실행-확인">3-2) 하둡 실행 확인</h4>

<p>localhost로 접속해서 하둡의 상태를 체크할 수 있다.</p>

<p>Cluster status : <a href="http://localhost:8088">http://localhost:8088</a>   <br />
HDFS status : <a href="http://localhost:9870">http://localhost:9870</a> <br />
Secondary NameNode status : <a href="http://localhost:9868">http://localhost:9868</a></p>

<p><img width="711" alt="스크린샷 2021-08-06 오후 11 15 02" src="https://user-images.githubusercontent.com/26623547/128523847-dbc654c6-c301-4e9d-add8-fbe332a48363.png" /></p>

<hr />

<p><strong>Reference</strong></p>

<p><a href="https://han-py.tistory.com/361">https://han-py.tistory.com/361</a><br />
<a href="http://www.incodom.kr/hadoop_%EC%B4%9D%EC%A0%95%EB%A6%AC">http://www.incodom.kr/hadoop_%EC%B4%9D%EC%A0%95%EB%A6%AC</a><br />
<a href="https://tariat.tistory.com/492">https://tariat.tistory.com/492</a><br />
<a href="https://rap0d.github.io/tip/2019/10/01/mac_hadoop_in_mac/">https://rap0d.github.io/tip/2019/10/01/mac_hadoop_in_mac/</a><br />
<a href="https://key4920.github.io/p/mac-os%EC%97%90-%ED%95%98%EB%91%A1hadoop-%EC%84%A4%EC%B9%98/">https://key4920.github.io/p/mac-os%EC%97%90-%ED%95%98%EB%91%A1hadoop-%EC%84%A4%EC%B9%98/</a></p>

<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://zcx6263.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

:ET