I"W+<h2 id="partitoning-이란">Partitoning 이란?</h2>

<p><code class="language-plaintext highlighter-rouge">RDD의 데이터는 클러스터를 구성하는 여러 서버(노드)에 나누어 저장된다. 
이때, 나누어진 데이터를 파티션이라는 단위로 관리한다.</code></p>

<p>RDD의 파티션은 RDD 데이터의 일부(조각 또는 슬라이스)를 의미한다. 예를 들어 
로컬 파일 시스템에 저장된 텍스트 파일을 스파크에 로드하면, 스파크는 파일 내용을 
여러 파티션으로 분할해 클러스터 노드에 고르게 분산 저장한다.</p>

<p>15줄짜리 텍스트 파일을 노드 다섯 개로 구성된 클러스터에 분산 저장해 
RDD를 구성한 예다. 15줄 짜리 파일이 노드 다섯 개에 분산되었으므로 
각 파티션에는 세 줄씩 저장된다. 스파크는 RDD별로 RDD의 파티션 목록을 
보관하며, 각 파티션의 데이터를 처리할 최적 위치를 추가로 저장할 수 있다.</p>

<p><img width="503" alt="스크린샷 2021-06-21 오후 5 00 47" src="https://user-images.githubusercontent.com/26623547/122727873-7b534b00-d2b2-11eb-869c-24218ec2fa60.png" /></p>

<p>HDFS를 사용하는 경우에는 기본적으로 HDFS 블록과 파티션이 1:1으로 
구성되지만 스파크 API를 사용하면 파티션의 크기와 수를 쉽게 
조정할 수 있다.</p>

<p>이렇게 파티션의 크기와 수를 조정하고 파티션을 배치하는 방법을 
설정하여 RDD의 구조를 제어하는 것을 파티셔닝 이라고 한다.</p>

<p>파티션의 크기나 수를 변경하느냐에 따라 어플리케이션의 성능이 
크게 변할 수 있으므로 스파크의 동작을 잘 이해하고 적절하게 
설정해야 한다.</p>

<blockquote>
  <p>스파크에서 올바른 파티셔닝 방법을 선택하는 것은 일반적으로 프로그래밍에서 올바른 
자료구조를 선택하는 것과 같다.</p>
</blockquote>

<h4 id="파티셔닝에-고려해야할-사항">파티셔닝에 고려해야할 사항</h4>

<p>파티셔닝이 모든 상황에 대해서 성능을 개선시켜주는 것은 아니다. RDD가 
단 한번만 스캐닝된다면 오히려 비효율적이므로 굳이 파티셔닝 할 필요가 없다.</p>

<p><code class="language-plaintext highlighter-rouge">파티셔닝은 조인 같은 키 중심의 Pair RDD연산에서 데이터 세트가 여러번 
재활용 될 때에만 의미가 있다.</code></p>

<p>파티셔닝은 앞서 언급한바와 같이 Spark의 성능에 
중요한 요소이다.</p>

<p>파티션의 개수는 클러스터의 CPU 코어의 개수에 따라 결정이 되고, 
    파티션을 효율적으로 하게되면 parallelism 을 증가시키고, 
    Worker 노드의 bottleneck의 위험을 줄일 수 있다.  <br />
또한, Worker노드 사이에 데이터 이동이 줄어들기 때문에 shuffling의 
cost도 절약할 수 있다.  <br />
shuffling은 OOM(Out Of Memory)의 위험이 있기 때문에 최소한으로 동작하게끔 
하는게 중요하다.</p>

<p><img width="438" alt="스크린샷 2021-06-21 오후 5 22 03" src="https://user-images.githubusercontent.com/26623547/122730495-3da3f180-d2b5-11eb-9db9-f24c83d7797f.png" /></p>

<p>위의 그림에서 첫번째 그림의 클러스터 환경은 코어 개수가 3개이고, 4개의 
파티션을 만들었다.  <br />
4000개의 record를 처리해야 한다고 할 때, 파티션이 4개이므로 1000개씩 분산되어 
저장했다고 가정하자. <br />
1000개를 처리하는게 하나의 task라고 하고 1시간이 소요된다고 가정했을 때, 
    이런 환경에서는 모든 task를 처리하기 위해 2시간이 소요될 것이다.</p>

<p>동시에 처리할 수 있는 코어 개수가 3개이기 때문에 3개의 파티션을 먼저 처리 한 후 
하나의 task를 완료한 코어에 의해 나머지 파티션을 처리하기 때문이다. <br />
이렇게 처리하게 되면 나머지 2개의 코어는 1시간동안 1개의 코어가 하나의 
task를 처리하는 시간 동안 아무런 처리를 하지 않게 된다.</p>

<p>그렇다면 파티션의 개수를 3개로 한다면 어떻게 될까?</p>

<p>각 파티션이 처리해야 하는 task는 3개이고, 각 task는 1300여개의 records를 
처리해야 한다.  <br />
기존에 1000개를 처리하는 것보다 처리해야 하는 양이 많아지지만, 한번에 
각 코어가 각 파티션을 처리가 가능하기 때문에 약 80분이면 모든 작업이 
완료 된다.</p>

<p><code class="language-plaintext highlighter-rouge">즉, 파티션의 개수는 spark에서 성능을 향상시키는데 중요한 요소이다. 2시간 
작업을 할 것인가. 파티셔닝을 잘해서 80분에 작업을 마칠것인가는 
개발자의 역량이다.</code></p>

<hr />

<h2 id="파티션과-관련된-연산">파티션과 관련된 연산</h2>

<h4 id="coalesce와-repartition">coalesce와 repartition</h4>

<p><code class="language-plaintext highlighter-rouge">RDD를 생성한 뒤 filter() 연산을 비롯한 다양한 트랜스포메이션 연산을
수행하다 보면 최초에 설정한 파티션 개수가 적합하지 않은 경우가
발생할 수 있다. 이 경우 coalesce()나 repartition() 연산을
사용해 현재의 RDD 파티션 개수를 조정할 수 있다.</code></p>

<p><code class="language-plaintext highlighter-rouge">두 메서드는 모두 파티션의 크기를 나타내는 정수를 인자로 받아서 파티션의 
수를 조정한다는 점에서 공통점이 있지만 repartition()이 파티션 수를 
늘리거나 줄이는 것을 모두 할 수 있는 반면 coalesce()는 줄이는 것만 가능하다.</code></p>

<p>이렇게 모든 것이 가능한 repartiton() 메서드가 있음에도 coalesce() 메서드를 
따로 두는 이유는 바로 처리 방식에 따른 성능 차이 때문이다. <br />
즉, repartition()은 셔플을 기반으로 동작을 수행하는데 반면 coalesce()는 
강제로 셔플을 수행하라는 옵션을 지정하지 않는 한 셔플을 사용하지 않기 
때문이다.  <br />
<code class="language-plaintext highlighter-rouge">따라서 데이터 필터링 등의 작업으로 데이터 수가 줄어들어 파티션의 수를 줄이고자 
할 때는 상대적으로 성능이 좋은 coalesce()를 사용하고, 파티션 수를 늘려야 
하는 경우에만 repartition() 메서드를 사용하는 것이 좋다.</code></p>

<p>즉, coalesce는 셔플링을 수행하지 않는 대신 데이터 이동을 최소화하려고 부모 RDD의 
기존 파티션을 최대한 보존한다.</p>

<p>참고로 파티션이 몇개로 분할되어 있는지 파티션 수를 확인하려면 아래와 같이 가능하다.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">df</span><span class="o">.</span><span class="py">rdd</span><span class="o">.</span><span class="py">getNumPartitions</span>   
<span class="nv">df</span><span class="o">.</span><span class="py">rdd</span><span class="o">.</span><span class="py">partitions</span><span class="o">.</span><span class="py">length</span>   
<span class="nv">df</span><span class="o">.</span><span class="py">rdd</span><span class="o">.</span><span class="py">partitions</span><span class="o">.</span><span class="py">size</span>   
</code></pre></div></div>

<p>Spark의 Task는 하나의 partition을 가진다. <br />
SparkContext의 parallelize를 실행해서 hadoop HDFS에 데이터를 저장할 때, 
    병렬(spark core) 개수만큼 파티션이 생긴다. 전문 용어로 level of parallelism이라 한다.</p>

<blockquote>
  <p>hadoop에서도 reduce 개수만큼 파티션 개수가 생긴다.</p>
</blockquote>

<p>HDFS에 저장할 용량이 크지 않다면 spark core 개수와 상관없이 하나의 
파티션 파일로 모아두는 것이 좋을 수 있다.</p>

<p>이를 위해 repartiton 또는 coalesce를 사용할 수 있다.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">df</span><span class="o">.</span><span class="py">repartition</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="py">write</span><span class="o">.</span><span class="py">format</span><span class="o">(</span><span class="ss">'cs</span><span class="n">v</span><span class="o">')</span>
<span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"path"</span><span class="o">,</span> <span class="s">"s3a://my.bucket.name/location"</span><span class="o">)</span>
<span class="o">.</span><span class="py">save</span><span class="o">(</span><span class="n">header</span> <span class="k">=</span> <span class="ss">'tru</span><span class="n">e</span><span class="o">')</span>
</code></pre></div></div>

<hr />

<p><strong>Reference</strong></p>

<p><a href="https://blog.devgenius.io/a-neglected-fact-about-apache-spark-performance-comparison-of-coalesce-1-and-repartition-1-80bb4e30aae4">https://blog.devgenius.io/a-neglected-fact-about-apache-spark-performance-comparison-of-coalesce-1-and-repartition-1-80bb4e30aae4</a><br />
<a href="https://jaemunbro.medium.com/apache-spark-partition-%EA%B0%9C%EC%88%98%EC%99%80-%ED%81%AC%EA%B8%B0-%EC%A0%95%ED%95%98%EA%B8%B0-3a790bd4675d">https://jaemunbro.medium.com/apache-spark-partition-%EA%B0%9C%EC%88%98%EC%99%80-%ED%81%AC%EA%B8%B0-%EC%A0%95%ED%95%98%EA%B8%B0-3a790bd4675d</a><br />
<a href="https://m.blog.naver.com/syung1104/221103154997">https://m.blog.naver.com/syung1104/221103154997</a><br />
<a href="https://thebook.io/006908/part01/ch04/02-01/">https://thebook.io/006908/part01/ch04/02-01/</a><br />
<a href="https://ourcstory.tistory.com/147">https://ourcstory.tistory.com/147</a><br />
<a href="https://knight76.tistory.com/entry/scala-spark%EC%97%90%EC%84%9C-partition-%EC%A4%84%EC%9D%B4%EA%B8%B0-repartition-coalesce">https://knight76.tistory.com/entry/scala-spark%EC%97%90%EC%84%9C-partition-%EC%A4%84%EC%9D%B4%EA%B8%B0-repartition-coalesce</a></p>

<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://zcx6263.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

:ET